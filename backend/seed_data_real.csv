title,description,difficulty,subcategory,technology,dataset_url,dataset_description,overview,task,outcomes,image_1,image_2,sample_sol
Missing Values,The classic Titanic dataset has missing values! Let's deal with those by thinking like a Data Scientist. ,Easy,"Imputation, Data Cleaning, Data Preparation","sklearn, pandas",https://drive.google.com/file/d/1Yl-g0zZB35wSm44Lt48hMbqJHK1GfK05/view?usp=share_link,The classic titanic dataset. 1309 rows with 13 features.,"In this challenge we will learn how to identify missing values in the data, and fill them in if needed with the appropriate statistic (mean, median, or mode). We will also learn when it might be necessary to drop a column entirely.  ","Step 1: Find out how many missing values are in each column. 
Step 2: Impute (Fill in with something) the missing values using mean, median, or mode in the columns you deem worth using. 
Step 3: Drop the columns that have too many missing values, above a threshold that seems reasonable. 
Step 4: Display the end result.   ",You have a dataset that has no missing values.,https://dsclimages.blob.core.windows.net/images/Titanic-in-Colour.jpg,https://dsclimages.blob.core.windows.net/images/titanicdata.png,https://github.com/thomasbritnell/dsclSolutions/blob/main/Easy/C13/solution.ipynb
Basic Outlier Detection,Detect the prescence of outliers in this financial corruption data.,Easy,"Outliers, Data Cleaning, Data Preparation","sklearn, pandas, matplotlib",https://drive.google.com/file/d/1jpVkIO0ADPJ3XkqCWzfq61mEXHMs2DQO/view?usp=share_link,"In an attempt to provide transparency to the population of Brazil, the dadosaberto initiative publishes data on different topics related to the House of Deputies. Among those informations, is the amount of refunds requested by each deputy, on expenses related to their activities.","In this challenge, we are going to identify outliers in data. In this case study, the outliers are deputies that are incurring a suspicious number of expenses. ","Step 1: Load and inspect the data to understand its structure and contents. 
Step 2: Check for and handle any missing values appropriately. 
Step 3: Identify the numerical columns that are relevant for detecting outliers. 
Step 4: Visualize the distribution of values in each numerical column to get a sense of potential outliers. 
Step 5: Apply a method to detect outliers, such as measuring how far values deviate from the typical range. 
Step 6: Decide how to handle the outliers, either by removing them, replacing them, or flagging them for later. 
Step 7: Re-visualize the cleaned data to ensure that the outliers were handled as intended.","Success in this task means accurately identifying specific rows (deputies!) that contain outlier values, based on statistical deviations from the norm, so they can be reviewed, flagged, or handled appropriately.",https://dsclimages.blob.core.windows.net/images/Marca_Camara_Preferencial_Cores.png,https://dsclimages.blob.core.windows.net/images/dirtydeputies.png,https://github.com/thomasbritnell/dsclSolutions/blob/main/Easy/C14/solution.ipynb
Column Data Type Conversion,Make the changes necessary to convert columns to appropriate data types,Easy,"Data Cleaning, Data Preparation",pandas,https://drive.google.com/file/d/1-f5OoYW2G7BifoAyUneMCqXtGweRU3si/view?usp=share_link,"A set of features used to predict the income of an individual, based on socioeconomic factors. 14 features and 48,000 rows.",With this dataset we will learn how to convert columns to their appropriate data types.,"Step 1: Load in the dataset. 
Step 2: Preview the data to see which features are numerical, and which are categorical.
Step 3: Convert these to appropriate types (e.g., strings to datetime, floats to integers).
Step 4: Validate the changes.","You will gain a well-structured dataset with correctly assigned data types, ready for statistical modeling and visualization.",https://dsclimages.blob.core.windows.net/images/adult1.jpg,,
Descriptive Statistics,"Report the mean, median, and mode of the target feature",Easy,"Statistics, Data Exploration","sklearn, pandas",https://drive.google.com/file/d/1oT-GfLG5PGNwLU50opcqS-VEpfi0N0CH/view?usp=share_link,"The Iris dataset contains measurements of 150 iris flowers from three species. It includes numerical features like petal length and sepal width, used for exploratory statistics and classification.",Statistical summaries help you understand the central tendency and spread of data. This challenge focuses on computing and interpreting key statistics before modeling.,"Step 1: Load the iris dataset and identify the target feature. 
Step 2: Extract the values of the target feature from the dataset. 
Step 3: Calculate the mean value of the target feature. 
Step 4: Calculate the median value of the target feature. 
Step 5: Determine the mode value of the target feature.","You will be able to describe your dataset statistically and detect skew, outliers, and central tendencies that influence modeling decisions.",https://dsclimages.blob.core.windows.net/images/iris1.jpg,https://dsclimages.blob.core.windows.net/images/iris.png,
Encoding Categorical Data,"Encode categorial data using one-hot encoding, or other methods",Easy,"Data Cleaning, Data Preparation","sklearn, pandas",https://drive.google.com/file/d/1k1zdwQkc1Bqbb7401iVKFAURNchCEt3R/view?usp=share_link,"The classic Titanic dataset. 1309 rows with 13 features. It includes information on passengers' age, sex, fare, and survival status.",Many machine learning algorithms require numerical input. You’ll convert categorical data (like gender or port of embarkation) into a usable numeric format.,"Step 1: Identify the categorical features in your dataset. 
Step 2: Choose an encoding method such as one-hot encoding or label encoding. 
Step 3: Apply the chosen encoding method to transform the categorical data into numerical format. 
Step 4: Replace the original categorical features with the encoded numerical features. 
Step 5: Verify that the encoding has been applied correctly and that the data is ready for analysis or modeling.",A fully encoded dataset that’s compatible with machine learning workflows.,https://dsclimages.blob.core.windows.net/images/Titanic-in-Colour.jpg,https://dsclimages.blob.core.windows.net/images/titanicdata.png,
Normalization and Scaling of Data,Perform appropriate normalization and/or scaling,Easy,Data Preparation,"sklearn, pandas",https://drive.google.com/file/d/1o0cmHTG9zQzQEjvRb_3lsm31I39iDWb0/view?usp=share_link,This dataset includes income and demographic attributes with wide numerical ranges. Scaling is essential for ensuring fair treatment of all features in machine learning.,"Machine learning models like KNN and SVM are sensitive to feature scale. In this task, you will practice techniques to normalize and standardize numerical variables.","Step 1: Identify the numerical features that require normalization or scaling. 
Step 2: Choose a suitable method such as min-max scaling or standardization based on your data and goals. 
Step 3: Apply the selected normalization or scaling technique to the chosen features. 
Step 4: Replace the original feature values with the normalized or scaled values. 
Step 5: Confirm that the transformed data maintains the intended properties and is ready for use.",You will understand how scaled features affect machine learning algorithms and be able to choose the right transformation based on context.,https://dsclimages.blob.core.windows.net/images/wineimge.jpg,https://dsclimages.blob.core.windows.net/images/wine.png,
Analyze service request frequency,Explore NYC 311 request patterns over time and location to detect service delay factors.,Medium,"Time Series, Feature Importance","pandas, matplotlib, seaborn, sklearn",https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9/about_data,"This public NYC 311 dataset includes millions of service requests submitted by residents. It contains timestamps, complaint types, and borough data, offering a great opportunity for temporal analysis.",You’ll analyze frequency patterns in citizen-submitted service requests to identify high-volume times and seasonal trends.,"Step 1: Load the dataset and parse Created Date as datetime.
Step 2: Group by day/week/month to compute the number of requests.
Step 3: Create line plots to visualize trends.
Step 4: Compare weekdays vs. weekends or seasonality across months.",You’ll learn to extract insights from temporal datasets and build visuals to support civic planning or operational decision-making.,https://dsclimages.blob.core.windows.net/images/311img.png,https://dsclimages.blob.core.windows.net/images/311.png,
Predict Titanic survival,Classify survival outcome using logistic regression and evaluate with confusion matrix and F1 score.,Medium,"Classification, Classification Metrics, Feature Importance","pandas, sklearn, numpy, matplotlib",https://www.kaggle.com/competitions/titanic/data,"The Titanic dataset includes demographic and survival information for passengers aboard the RMS Titanic. It’s commonly used for binary classification problems in machine learning.
","Using logistic regression, you'll predict whether a passenger survived the Titanic disaster based on features like age, gender, and ticket class.","Step 1: Load and explore the dataset.
Step 2: Perform data cleaning (handle missing values, encode categorical data).
Step 3: Build a logistic regression model to predict survival.
Step 4: Evaluate accuracy using confusion matrix and ROC curve.","A trained binary classifier that predicts survival with interpretability, based on logistic regression.
",https://dsclimages.blob.core.windows.net/images/Titanic-in-Colour.jpg,https://dsclimages.blob.core.windows.net/images/titanicdata.png,
Heart disease prediction,Predict presence of heart disease and analyze which features matter most.,Medium,"Classification, Regression, Feature Importance","pandas, sklearn, numpy, shap, matplotlib, seaborn",https://www.kaggle.com/datasets/cherngs/heart-disease-cleveland-uci,"This dataset contains 303 patient records with 14 features related to clinical data such as blood pressure, cholesterol, and heart rate.","In this challenge, we will build a model that can predict whether a patient has heart disease based on clinical measurements.","Step 1: Load the heart disease dataset.
Step 2: Normalize and encode relevant features.
Step 3: Train a Random Forest classifier.
Step 4: Evaluate the model using F1-score and ROC curve.
",You have a classifier that can predict heart disease based on key medical indicators.,https://dsclimages.blob.core.windows.net/images/heartimg.jpg,https://dsclimages.blob.core.windows.net/images/heart.png,
Loan approval classification,Use decision trees to predict loan outcomes and assess model performance using precision/F1.,Medium,"Classification, Classification Metrics, Feature Importance","pandas, sklearn, numpy, matplotlib",https://www.kaggle.com/datasets/altruistdelhite04/loan-prediction-problem-dataset,"This dataset has 614 loan applications with 13 features including applicant income, loan amount, and credit history.","In this challenge, we will train a model to classify whether a loan will be approved using applicant details.","Step 1: Load and clean the loan dataset.
Step 2: Handle missing values and encode categorical data.
Step 3: Train a decision tree classifier.
Step 4: Evaluate the model using accuracy and feature importance.",You have a model that predicts loan approvals and explains key decision features.,https://dsclimages.blob.core.windows.net/images/loanimg.png,https://dsclimages.blob.core.windows.net/images/loan.png,
Retail sales forecasting,Apply regression to forecast future sales and evaluate using R².,Medium,"Time Series, Regression","pandas, sklearn, numpy, matplotlib, statsmodels",https://www.kaggle.com/competitions/m5-forecasting-accuracy/data,"The dataset contains daily sales for Walmart items across multiple stores. It includes over 1 million records with dates, departments, and sales.","In this challenge, we will learn to forecast future sales using historical data and time series modeling techniques.","Step 1: Load the retail sales dataset.
Step 2: Aggregate and visualize sales trends.
Step 3: Train a regression or ARIMA model.
Step 4: Validate predictions using RMSE.",You have a model that forecasts future sales based on past retail trends.,https://dsclimages.blob.core.windows.net/images/walmartimg.jpeg,,
Build a recommender system,Use clustering and feature similarity to suggest tracks for a user from the Spotify dataset.,Hard,"Clustering, Recommender Systems, Feature Importance","pandas, sklearn, numpy, seaborn, scipy",https://www.kaggle.com/datasets/zaheenhamidani/ultimate-spotify-tracks-db,"This dataset includes Spotify track features such as tempo, energy, and genre. It contains 32,000 songs with 18 audio-based features.","In this challenge, we will build a recommender system that suggests songs based on their audio similarity.","Step 1: Load the Spotify dataset and normalize the features.
Step 2: Cluster tracks using KMeans.
Step 3: Use cosine similarity to generate recommendations.
Step 4: Test the recommender using selected songs.","You have a basic recommender system that returns similar tracks based on song characteristics.
",https://dsclimages.blob.core.windows.net/images/spotify.png,https://dsclimages.blob.core.windows.net/images/spotifyimg.png,
Detect fraudulent transactions,Use classification models to find anomalies in credit card transaction data.,Hard,"Anomaly Detection, Classification Metrics","pandas, sklearn, numpy",https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud,"This dataset contains credit card transactions labeled as fraudulent or legitimate. It includes 284,807 transactions with 30 anonymized features.","In this challenge, you'll train a model to detect fraudulent activity in credit card transactions using classification techniques on imbalanced data.","Step 1: Load and explore the dataset.
Step 2: Handle class imbalance using resampling or SMOTE.
Step 3: Train a classification model (e.g., logistic regression, XGBoost).
Step 4: Evaluate model performance with precision-recall and AUC-ROC.",You have a model that flags fraudulent transactions with strong recall and minimal false positives.,https://dsclimages.blob.core.windows.net/images/creditimg.jpeg,https://dsclimages.blob.core.windows.net/images/credit.png,
Sentiment analysis on reviews,Use NLP to classify food review sentiment and identify influential review words.,Hard,"NLP, Sentiment Analysis, Feature Importance","pandas, sklearn, nltk",https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews,"This dataset contains Amazon food reviews with text data and sentiment labels. It includes over 500,000 reviews with corresponding star ratings.
","In this challenge, you'll apply natural language processing (NLP) techniques to predict review sentiment from raw text data.","Step 1: Preprocess text (tokenization, stopword removal, vectorization).
Step 2: Train a text classification model (Naive Bayes or Logistic Regression).
Step 3: Evaluate performance using accuracy and F1-score.
Step 4: Visualize word importance with word clouds or feature weights.",You have a working sentiment classifier and an understanding of key words driving predictions.,https://dsclimages.blob.core.windows.net/images/amazonimg.jpg,https://dsclimages.blob.core.windows.net/images/amazon.png,
Movie recommender system,Cluster similar Netflix content and recommend based on user viewing history.,Hard,"Recommender, Clustering","pandas, sklearn, numpy, surprise, seaborn",https://www.kaggle.com/datasets/shivamb/netflix-shows,"This dataset contains user ratings for Netflix content, with fields like user ID, movie ID, rating, and genre. It’s ideal for collaborative filtering.","In this challenge, you'll build a recommender system that suggests movies to users based on historical rating patterns.","Step 1: Load and explore user-movie rating matrix.
Step 2: Apply collaborative filtering or matrix factorization.
Step 3: Use cosine similarity or SVD to generate recommendations.
Step 4: Evaluate recommendations with precision@k or RMSE.","You have a recommender system that provides personalized suggestions based on user preferences.
",https://dsclimages.blob.core.windows.net/images/netfliximg.png,https://dsclimages.blob.core.windows.net/images/netflix.png,
Digit classification (MNIST),Train a neural net to classify handwritten digits 0–9.,Hard,"Deep Learning with Neural Nets, Classification","tensorflow, keras, numpy, matplotlib, opencv",https://www.geeksforgeeks.org/fashion-mnist-with-python-keras-and-deep-learning/,"The MNIST dataset contains 70,000 grayscale images of handwritten digits (0–9), each 28x28 pixels in size.",This challenge involves building a neural network to classify handwritten digits using deep learning techniques.,"Step 1: Load and normalize image data.
Step 2: Build a neural network using TensorFlow or Keras.
Step 3: Train the model on labeled images.
Step 4: Evaluate performance with accuracy and confusion matrix.","You have a deep learning model that accurately recognizes handwritten digits from images.
",https://dsclimages.blob.core.windows.net/images/fashion.png,https://dsclimages.blob.core.windows.net/images/fashion.png,
Object classification (CIFAR-10),Use a CNN to classify small colored images across 10 classes.,Hard,"Deep Learning with Neural Nets, Classification","tensorflow, keras, numpy, matplotlib, opencv",https://www.geeksforgeeks.org/cifar-10-image-classification-in-tensorflow/,"The CIFAR-10 dataset contains 60,000 color images across 10 classes like airplanes, cats, and trucks. Each image is 32x32 pixels.
","In this challenge, you'll build a convolutional neural network (CNN) to classify objects in colored images.","Step 1: Load and preprocess the CIFAR-10 image dataset.
Step 2: Design a CNN architecture in Keras or TensorFlow.
Step 3: Train and tune the model using validation data.
Step 4: Evaluate performance using test accuracy and learning curves.
","You have a trained CNN that can accurately classify multiple object types from images.
",https://dsclimages.blob.core.windows.net/images/cifar10.png,https://dsclimages.blob.core.windows.net/images/cifar10.png,
Image classification (ImageNet),Train a deep learning model to classify complex images from large-scale categories.,Hard,"Deep Learning with Neural Nets, Classification","tensorflow, keras, pytorch, numpy",https://www.geeksforgeeks.org/vgg-16-cnn-model/,"The ImageNet dataset contains over 14 million labeled images across 20,000 categories. It's commonly used to train deep convolutional neural networks on complex object classification tasks.","In this challenge, you will build a deep learning model to classify real-world images using a pre-trained network such as VGG-16 or ResNet. You’ll work with high-dimensional image data and explore transfer learning.","Step 1: Load a pre-trained model (e.g., VGG-16) using Keras or PyTorch.
Step 2: Prepare and preprocess ImageNet-format data or a sample subset.
Step 3: Fine-tune the model for selected categories using transfer learning.
Step 4: Evaluate model performance using top-1/top-5 accuracy and confusion matrix.","You have a trained image classification model capable of identifying a wide range of objects in complex images using state-of-the-art deep learning.
",,,